#!/bin/bash

LINE_ARGUMENTS=$#

if [[ $LINE_ARGUMENTS -eq 0 ]]; then
    export ABS_PATH=`pwd`

    JUDGECLASS="toyDataset"
    
else
    SKIP_DATA_EXTRACTION=$1; shift
    JUDGECLASS=$1; shift
    PRINT=$1; shift
    TOPICS_CONSIDERED=("$@");
    rules=5
    

fi

source "${ABS_PATH}/handle_errors"
source "${ABS_PATH}/colors"
if [[ $PRINT == "y" ]]; then
    echo "${ABS_PATH}/handle_errors"
fi


PURPOSE=baseline

CORPLIST=("${JUDGECLASS}")
SOFIA="${ABS_PATH}/sofia-ml-read-only/sofia-ml"
if [[ $PRINT == "y" ]]; then
    echo $JUDGECLASS
fi
contains() {
    : '
        Utility function that returns true if a given
        value is within the given array and false otherwise.

        $1 -> value to check
        $2... -> array
    '


    value=$1; shift
    array=("$@")

    for v in "${array[@]}"; do
        if [[ $v == $value ]]; then
            true
            return
        fi
    done

    false
    return
}

: '
    Iterate over items in CORPLIST
'
for CORP in "${CORPLIST[@]}"; do


    echo -e "${BLUE}Working on topic $CORP...${END}"
    pushd Corpus # pushd <dir> é semelhante à cd <dir>
    
    
    echo -e "${BLUE}Preparando dataset...${END}"

    if [[ $LINE_ARGUMENTS -gt 0 ]]; then
        if [[ $SKIP_DATA_EXTRACTION == "false" ]]; then
            ./dofast4 "$CORP" $PRINT
            cp "$CORP".df ../"$CORP".df > /dev/null

            cp "$CORP".svm.fil ../"$CORP".svm.fil 
            echo -e "${GREEN}  runing feature compression SVD"
    
            ../svd/./script_create_svd.sh  ../$CORP.svm.fil 10    
            
        fi
#     else
#        # ./dofast4 "$CORP" $PRINT
    fi

    
    
    
    
        
    popd # popd é semelhante ao cd ..    
        
    
    : '
        Iterates over all `topic:query` pairs within
        judgement/$CORP.topic.stemming.txt
    '
    while IFS='' read -r line || [[ -n $line ]]; do

        IFS=':' read -ra TEXT <<< "$line"

        TOPIC="${TEXT[0]}"
        echo -e "${BLUE}Working on topic ${TOPICS_CONSIDERED[@]}...${END}"
        # Skips topics not considered
        if [[ $LINE_ARGUMENTS -gt 0 ]]; then
            if ! contains $TOPIC "${TOPICS_CONSIDERED[@]}"; then
                echo -e "${YELLOW}Skipping topic '$TOPIC'.${END}"
                continue
            fi
        fi
        
        QUERY="${TEXT[1]}"

        : '
            Checks if the TOPIC or QUERY are empty
        '
        if [[ -z $TOPIC ]]; then
            throw $EMPTY_VARIABLE_EXCEPTION "Variable TOPIC is empty"

        elif [[ -z $QUERY ]]; then
            throw $EMPTY_VARIABLE_EXCEPTION "Variable QUERY is empty"

        fi

        echo -e "${WHITE}Topic${END}:$TOPIC"
        echo -e "${WHITE}Query${END}:$QUERY"

        if [[ $PRINT == "n" ]]; then
            echo -e "${RED}     Método em execução..."
        fi

        ######
        if [[ $PRINT == "y" ]]; then
            echo "Creating directories to store results..."
        fi

        try 
        (
            rm -rf result/"$PURPOSE"/"$CORP"/"$TOPIC"/
            mkdir -p result/"$PURPOSE"/"$CORP"/
            mkdir -p result/dump/"$PURPOSE"/"$CORP"/

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }

        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
            echo "Creating topic directory topic (${TOPIC})..."
        fi
        ######
        
        try 
        (
            rm -rf $TOPIC
            mkdir $TOPIC
            #echo "cat judgement/qrels.$CORP.list | grep $TOPIC  | cut -d' ' -f3 > $TOPIC/goldendb"
            cat judgement/qrels.$CORP.list | grep $TOPIC  | cut -d' ' -f3 | sort > $TOPIC/goldendb

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
        
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
            echo "Creating file 'N' with number of documents..."
        fi
        ######
        
        try 
        (
            : '
                Creates a `N` file with number of all docs
            '
            echo `wc -l < "$CORP".svm.fil` > N

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
        
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
            echo "Preparing 'docfils' file with all documents..."
        fi    
        
        pushd $TOPIC

        echo "$QUERY" > "$TOPIC".seed.doc

        ######
        ln -n ../$CORP.svm.fil $CORP.svm.fil
        
        try 
        (
            cut -d' ' -f1 ../$CORP.svm.fil | sed -e 's/.*/& &/' > docfil
            cut -d' ' -f1 docfil | cat -n > docfils

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
            echo "Preparing relevance calculation files..."
        fi
        : '
            The `new$N` files keeps the files used on
                the $N-th iteration
        '

        ######
        try 
        (
            touch rel.$TOPIC.fil
            touch prel.$TOPIC

            rm -rf prevalence.rate
            touch prevalence.rate

            rm -rf rel.rate
            touch rel.rate

            rm -f new[0-9][0-9].$TOPIC tail[0-9][0-9].$TOPIC self*.$TOPIC gold*.$TOPIC
            touch new00.$TOPIC

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
        fi
        # Total number of documents
        NDOCS=`cat docfils | wc -l`
        # Number of documents already labeled
        NDUN=0
        # Number of documents to be labeled in the current iteration
        L=1

        R=100
        LAMBDA=0.0001
        NotRel=0
        flag_discretize=0
        flag_allac_first_time=0
        : '
            $TOPIC.seed.doc stores the $TOPIC query
        '

        cp $TOPIC.seed.doc ../$TOPIC.seed.doc

        popd
        if [[ $PRINT == "y" ]]; then
            echo -e "${BLUE}Executing ./dofeaturesseed4...${END}"
        fi
        ./dofeaturesseed $TOPIC.seed.doc $TOPIC $CORP $PRINT 
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Finished ./dofeaturesseed4${END}"
            
        fi
        pushd $TOPIC

        ######
        try 
        (
            sed -e 's/[^ ]*/0/' ../$CORP.svm.fil | ../dosplit
            echo  "Preparing ../$CORP.svm.fil (runs ../dosplit) "

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
        
        try 
        (
            sed -e 's/[^ ]*/1/' svm.$TOPIC.seed.doc.fil > $TOPIC.synthetic.seed
            echo  "Preparing $TOPIC.synthetic.seed..."

        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
    
        
        #key value database kissdb             
            KEYSIZE=$(awk 'BEGIN{a=0}{len = length($1); a=a<len?len:a}END{print a}' $CORP.svm.fil)
            VALSIZE=$(awk 'BEGIN{a=0}{len = length($0); a=a<len?len:a}END{print a}' $CORP.svm.fil)
            KEYSIZE=$((KEYSIZE+2))
            VALSIZE=$((VALSIZE+2))  
      
         try 
        (
        
            
            
            
            
            if [ ! -f "../$CORP.db" ]; then              
                
                if [[ $PRINT == "y" ]]; then
                    echo "Indexing $CORP, keysize = $KEYSIZE, valsize = $VALSIZE"                       
                fi
                
                ../indexer $CORP.svm.fil "$CORP".db $KEYSIZE $VALSIZE || (echo "Error creating db"; exit 1)
            fi


        ) 2> $STD_ERROR_OUT

        catch || {
            exit_on_error
        }
    
        
        

         
#             fi
#         fi
        #pushd $TOPIC
        
        if [[ $PRINT == "y" ]]; then
            echo -e "${GREEN}Done.${END}"
        fi

        for x in 0 1 2 3 4 5 6 7 8 9 ; do

            for y in 0 1 2 3 4 5 6 7 8 9 ; do

                if [ $NDUN -lt $NDOCS ] ; then
                    export N=$x$y
                   
                    echo "Runing round number  $N with $((NDOCS-NDUN)) documents"
                    ######
                    if [[ $PRINT == "y" ]]; then
                        echo "Preparing trainset..."
                    fi                   

                    
                    
                    try 
                    (
                        cp $TOPIC.synthetic.seed trainset

                        cut -f2 docfils | shuf -n $R | sort | .././indexer "$CORP".db $KEYSIZE $VALSIZE | sed -e's/[^ ]*/-1/' >> trainset
                        
                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Done.${END}"
                        echo "Preparing seed (and x)... `wc -l < trainset`"
                       #  exit_on_error
                    fi
                    ######
                    try 
                    (
                        #cat sub_new[0-9][0-9].$TOPIC > seed
                        cat ssarp* > seed
                        #cat seed | sort | join - rel.$TOPIC.fil | sed -e 's/^/1 /' > x
                        #cat seed | sort | join -v1 - rel.$TOPIC.fil | sort -R | head -50000 | sed -e 's/^/-1 /' >> x
                        
                        cat seed | sort | join - rel.$TOPIC.fil | sed -e 's/^/1 /' | sort | uniq > x
                        cat seed | sort | join -v1 - rel.$TOPIC.fil | shuf -n 50000 | sed -e 's/^/-1 /' | sort | uniq  >> x

                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Done. ${END} "
                        echo "Preparing trainset (pt 2)... `wc -l < trainset`"
                    fi
                    ######
                    try 
                    (
                        #sort -k2 x | join -12 - ../$CORP.svm.fil | cut -d' ' -f2- | sort -n >> trainset
                        cut -d' ' -f2 x | .././indexer $CORP.db $KEYSIZE $VALSIZE | cut -d' ' -f2- | paste -d' ' <(cut -d' ' -f1 x) - | sort -n >> trainset

                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Done.${END}"
                    fi
                    # Calculate relevant documents prevalence rate in the traning set
                    RELTRAINDOC=`grep -E "^1\b" trainset | wc -l`

                    NOTRELTRAINDOC=`grep -E "^-1\b" trainset | wc -l`

                    PREVALENCERATE=`echo "scale=4; $RELTRAINDOC / ($RELTRAINDOC + $NOTRELTRAINDOC)" | bc`

                    echo $RELTRAINDOC $NOTRELTRAINDOC $PREVALENCERATE >> prevalence.rate

                    ######
                    if [[ $PRINT == "y" ]]; then
                        echo "Training (Running SOFIA-ML)... `wc -l < trainset`"
                    fi
                    try 
                    (


                        $SOFIA --learner_type logreg-pegasos --loop_type roc --lambda $LAMBDA --iterations 2000000 --training_file trainset --dimensionality 3300000  --model_out svm_model &> saida_classificador


                        RES=$?

                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }

                    
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Finished SOFIA-ML.${END}"
                        echo $RES
                    fi
                    
                    MAXTHREADS=5                    
                    if [[ "$RES" -eq "0" ]] ; then
                        for z in svm.test.* ; do

                            ######

                            
                            while [ "$(jobs | grep 'Running' | wc -l)" -ge "$MAXTHREADS" ]; do
                                sleep 1
                            done   
                         
                            
                            
                            try 
                            (

                                $SOFIA --test_file $z --dimensionality 3300000 --model_in svm_model --results_file pout.$z &> saida_classificador & 


                            ) 2> $STD_ERROR_OUT

                            catch || {
                                echo $ERROR_CODE
                                exit_on_error
                            }
                           
                        done

                        wait
                        #waiting all threads complete their work

                    else
                        ######
                       
                        try 
                        (
                            rm -f pout.svm.test.*
                            cut -f2      | sort -R | cat -n | sort -k2 | sed -e 's/ */-/' > pout.svm.test.1

                        ) 2> $STD_ERROR_OUT


                        if [[ $PRINT == "y" ]]; then
                            echo -e "${GREEN}Done.${END}"
                        fi
                    fi

                    ######
                    if [[ $PRINT == "y" ]]; then
                        echo "Starting SCAL process $N\nPreparing ranking.$N.$TOPIC..."
                    fi
                    
                    
                    try 
                    (
                        cat new[0-9][0-9].$TOPIC > seed.$TOPIC
                        cut -f1 pout.svm.test.* | ../fixnum | cat -n | join -o2.2,1.2 -t$'\t' - docfils | sort -k1 -n  > inlr.out.$N.$TOPIC
                        if [[ $PRINT == "y" ]]; then
                            echo -e "${BLUE}\tinlr.out size =`wc -l < inlr.out.$N.$TOPIC` docfils  `wc -l <docfils `${END}"
                        fi
                        sort -n seed.$TOPIC > temp
                        cat temp | join  -v2 - inlr.out.$N.$TOPIC -2 1 | shuf |  sort -k 2 -r -g -s  > ranking.$N.$TOPIC
                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Done.${END}"
                        echo "Preparing new$N.$TOPIC..."
                    fi

                    ######
                    try 
                    (
                        if [[ $PRINT == "y" ]]; then
                            echo -e "${BLUE}\tranking size `wc -l < ranking.$N.$TOPIC`${END}"
                        fi
                        cat ranking.$N.$TOPIC | cut -d' ' -f1 > new$N.$TOPIC
                        cp new$N.$TOPIC U$N

                        cat new[0-9][0-9].$TOPIC > x

                        if [ "$N" != "99" ] ; then
                            head -$L new$N.$TOPIC > y
                            mv y new$N.$TOPIC
                        fi

                    ) 2> $STD_ERROR_OUT

                    catch || {
                        exit_on_error
                    }
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Done.${END}"
                    fi
                    : '
                        x armazena new($N - 1).$TOPIC
                    '

                    # Limits the number of documents by 30
                    if [ $L -le 30 ]; then
                        b=$L
                    else
                        b=30
                    fi

                    : '
                        The files sub_new$N represents a sample of at most 30
                            documents from the documents to be used in the iteration.
                    '
                    shuf -n $b new$N.$TOPIC > sub_new$N.$TOPIC
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${BLUE}Number of labeled pairs: `wc -l < sub_new$N.$TOPIC`${END}"
                    fi
                    
                 
                   
                 
                 
                    # judgefile tells which are the positive docs
                    python2.7 ../doJudgementMain.py --topic=$TOPIC --judgefile=../judgement/qrels.$JUDGECLASS.list --input=sub_new$N.$TOPIC --output=rel.$TOPIC.Judged.doc.list --record=$TOPIC.record.list

                    # rel.$TOPIC.Judged.doc.list contains the current relevant docs

                    cat rel.$TOPIC.Judged.doc.list >> rel.$TOPIC.fil
                    cat rel.$TOPIC.Judged.doc.list > rel.$TOPIC.$N.Judged.doc.list
                    sort rel.$TOPIC.fil | uniq > temp
                    mv temp rel.$TOPIC.fil 
                 
                    
                 
                 
                    if [[ $PRINT == "y" ]]; then
                        echo -e "${GREEN}Starting active learning${END}"
                        
                    fi        
                 ############active learning
                    
        
                    if [ "$NotRel" -lt 3 ] || [ "$Rel" -lt 1000 ]
                    then            
                        
                        echo "store seed in ssarp file"
                        
                        cp sub_new$N.$TOPIC ssarp$N.$TOPIC
                        cat sub_new$N.$TOPIC  | sort | uniq | join - rel.$TOPIC.fil | cut -d' ' -f1 | sed -e 's/^/1 /' > x_posit.$N
                    
                        cat sub_new$N.$TOPIC   | sort | uniq | join - rel.$TOPIC.fil -v1 | cut -d' ' -f1 | sed -e 's/^/-1 /' > x_negat.$N

                        
                        
                        
                        cat  x_negat.*   |  sort -k2  | join - ../$CORP.svm.fil.svd   -2 1 -1 2 > seed_ssarp.$TOPIC            
                        
                        
                        cat  x_posit.* | shuf -n 1 | sort -k2  | join - ../$CORP.svm.fil.svd  -2 1 -1 2 >> seed_ssarp.$TOPIC

                    
                        cut -d ' ' -f2- seed_ssarp.$TOPIC  > seed_ssarpB.$TOPIC
            #        

                        cp x_posit.$N sub_new_positivo.$N
                        cp x_negat.$N sub_new_negativo.$N
                        ssarp_relevants=`wc -l < x_posit.$N`
                    else

                        echo "creating files"
                        
                        cat sub_new$N.$TOPIC | sort | uniq | join - rel.$TOPIC.fil | cut -d' ' -f1 | sed -e 's/^/1 /' > temp_posit.$N.$TOPIC
                        cat sub_new$N.$TOPIC | sort | uniq | join - rel.$TOPIC.fil -v1 | cut -d' ' -f1 | sed -e 's/^/-1 /' > temp_negat.$N.$TOPIC

                    
                        cat temp_posit.$N.$TOPIC temp_negat.$N.$TOPIC |  sort -k2  | join - ../$CORP.svm.fil.svd  -2 1 -1 2 > trainset.$N.$TOPIC
                        cut -d ' ' -f2- trainset.$N.$TOPIC  > trainsetB.$N.$TOPIC



                        if [ "$flag_discretize" -eq '0' ]
                        then
                            echo "gerando os bins\n"
                            echo "python3 ../svd/convert_txt.py ../$CORP.svm.fil.svd /tmp/total.$TOPIC.arff rel.$TOPIC.fil   "
                            python3 ../svd/convert_txt.py ../$CORP.svm.fil.svd /tmp/total.$TOPIC.arff rel.$TOPIC.fil        
            
                            cd ../SSARP/run/
                            rm train*
                            .././gera_bins_TUBE.sh /tmp/total.$TOPIC.arff  50 10 10
                            cd -
                            echo "saindo da geração dos bins"
                            flag_discretize=1
                        fi

                        echo "convertendo arquivo para txt"
                            python3 ../svd/convert_txt.py trainsetB.$N.$TOPIC out.$N.$TOPIC.arff rel.$TOPIC.fil
                            python3 ../svd/convert_txt.py seed_ssarpB.$TOPIC seed_out.$N.$TOPIC.arff rel.$TOPIC.fil

                    
                            cp trainset.$N.$TOPIC ../SSARP/run/
                            cp seed_out.$N.$TOPIC.arff ../SSARP/run/
                            cp out.$N.$TOPIC.arff ../SSARP/run/
                       
                       
                        echo "executando alac $rules"
                            cd ../SSARP/run/
                            ./SSARPX.sh out.$N.$TOPIC trainset.$N.$TOPIC 50 $N seed_out.$N.$TOPIC.arff $TOPIC $flag_allac_first_time $rules
                            flag_allac_first_time=$(($flag_allac_first_time+1))
                            cat label.$N.$TOPIC > /tmp/ssarp$N.$TOPIC
                            cd -
                            mv /tmp/ssarp$N.$TOPIC .    
                
                            cat sub_new$N.$TOPIC  | sort | uniq | join - rel.$TOPIC.fil | cut -d' ' -f1 | sed -e 's/^/1 /' > sub_new_positivo.$N
                            cat sub_new$N.$TOPIC   | sort | uniq | join - rel.$TOPIC.fil -v1 | cut -d' ' -f1 | sed -e 's/^/-1 /' > sub_new_negativo.$N

                            cat ssarp$N.$TOPIC   | sort | uniq | join - rel.$TOPIC.fil | cut -d' ' -f1 | sed -e 's/^/1 /' > x_posit.$N
                            cat ssarp$N.$TOPIC   | sort | uniq | join - rel.$TOPIC.fil -v1 | cut -d' ' -f1 | sed -e 's/^/-1 /' > x_negat.$N

                            cat x_posit.$N x_negat.$N | cut -d' ' -f2 | sort | uniq > ssarp$N.$TOPIC
                            ssarp_relevants=`wc -l < x_posit.$N`
                        
                            echo "docs positivos coletados `wc -l < x_posit.$N`   docs negativos ----  `wc -l < x_negat.$N` --- total docs positivos `wc -l < sub_new_positivo.$N`"
                            
                        fi
                        
                        
                        
                    aux=`wc -l < x_negat.$N`
                    NotRel=$(($NotRel+$aux))               
    #                     
                    if [[ $PRINT == "y" ]]; then
                        echo "End of active learning step" 
                    fi    
                    ###########################################
                    
                   

                    RELFINDDOC=`wc -l < x_posit.$N`
                    RELRATE=`echo "scale=4; $RELFINDDOC / $L" | bc`
                    CURRENTREL=`cat  x_posit.[0-9][0-9] | wc -l`

                    alreadyLabeledDocs=`cat ssarp*  | wc -l`
                    allDocs=`cat new[0-9][0-9].$TOPIC  | wc -l`
                    
                    if [[ $PRINT == "y" ]]; then
                        echo "rel $RELFINDDOC L $L b $b  alreadyLabeledDocs $alreadyLabeledDocs  allDocs $allDocs REL $RELRATE CURRENTREL $CURRENTREL relevant docs `wc -l < rel.$TOPIC.fil` "
                    fi
                    
                    aux=$((($RELFINDDOC*$L)/$b))
                    Rel=$(($Rel+$aux*1000))

                    echo $RELFINDDOC $L $b $RELRATE $CURRENTREL >> rel.rate
                    sort rel.$TOPIC.fil | sed -e 's/$/ 1/' > prel.$TOPIC

                    cut -d' ' -f1 prel.$TOPIC > rel.$TOPIC.fil
                    
                    if [[ $PRINT == "y" ]]; then
                        echo "compute the Estimate ρ̂  of each round" 
                    fi
                    
                    Temp_A=$(($RELFINDDOC*$L))
                    Temp_B=$(($Temp_A/$b))
                    
                    export Estimate=$(($Estimate+$Temp_B))                    
                    echo "${N%.*} $Estimate" >> store_estimation
                    
                    echo -e "${GREEN} $Temp_A $Temp_B $b $L Estimate rate is $Estimate"
                    
                    NDUN=$((NDUN+L))
                    L=$((L+(L+9)/10))
                fi
            done
        done
         
        
        echo "select the top 95% relevant documents  from the last ranking"
        echo " 20: Estimate ρ̂ = 1.05 "
        export prevalence=`echo "scale=5; ($Estimate * 1.05) / $NDOCS  " | bc`
        echo "prevalence $prevalence"        
        export m=`echo "scale=5; ($prevalence * $NDOCS ) * 0.90 " | bc`           
        prevalence_int=${m%.*}
        
        python3 ../selectRound.py store_estimation $prevalence_int
       
       
        export j=`cat flagOut`
        
        export t=`wc -l < U$j`
         
         
         
         
        NumberDocument=$(($NDOCS-$t))
        sort -k 2 -n inlr.out.$N.$TOPIC > sorted_ranking
        tail -$NumberDocument sorted_ranking | cut -d$'\t' -f1 > result_ranking.$TOPIC
        
        n=$(($NDOCS-$prevalence_int))
        tail -$NDOCS sorted_ranking | cut -d' ' -f1 | head -$n > result_plus.$TOPIC


        cat ssarp* result_ranking.$TOPIC >> result.$TOPIC 
        echo "valor t =$t valor j =$j valor NumberDocument =$NumberDocument NDOCS=$NDOCS"


        export relNumber=`cat result.$TOPIC | sort | uniq | join - goldendb | uniq | wc -l`
        NumberDocument=`cat result.$TOPIC | sort | uniq | wc -l`

       
        
        
        total=`wc -l < goldendb`
        recall=`echo "scale=5; ($relNumber / $total)" | bc`
        precisao=`echo "scale=5; ($relNumber / $NumberDocument)" | bc`
        echo "resultado final $relNumber ------$NumberDocument  recall $recall  precisao $precisao"     
        
        
        
        
        echo -e "${BLUE}calling second sampling strategy proposed by REVEAL ${END}"
        ../script_select_pairs.sh $TOPIC $JUDGECLASS $prevalence_int $rules 20
        
        
#         rm -rf svm.test.*


         popd

=======

# 
#         mv $TOPIC result/"$PURPOSE"/"$CORP"/$TOPIC
#         rm $TOPIC.seed.doc

    done < "judgement/$CORP.topic.stemming.txt"

   # echo -e "${WHITE}Apos finalizar o método o numero de docs recuperados do método  será o top total documentos acessados até a ultima executação que encontrou documentos relevantes. Por exemplo, se a execução N =20 foi a ultima a achar documentos releventas na amostragem deve-se pegar os top ~300 como relevantes. Essa será saida do método. Ou seja, o arquivo rel.rate armazena os relevantes recuperados, é só usar ele para implementar isso.${END}"


    #rm -rf "$CORP".svm.fil
    #rm "$CORP".df

    #rm N

    # Generate LSI from tfdf
    # python clustering/doLSI.py --input=tfdf_oldreut --output=LSIVector/"$CORP".lsi.dump --mapping=LSIVector/"$CORP".mapping.dump --latent=200 --choice=entropy --normalization=yes

done
