Noise reduction and convergence of Bayesian algorithms with blobs based on the Huber function and median root prior. Iterative image reconstruction algorithms have the potential to produce low noise images. Early stopping of the iteration process is problematic because some features of the image may converge slowly. On the other hand, there may be noise build-up with increased number of iterations. Therefore, we examined the stabilizing effect of using two different prior functions as well as image representation by blobs so that the number of iterations could be increased without noise build-up. Reconstruction was performed of simulated phantoms and of real data acquired by positron emission tomography. Image quality measures were calculated for images reconstructed with or without priors. Both priors stabilized the iteration process. The first prior based on the Huber function reduced the noise without significant loss of contrast recovery of small spots, but the drawback of the method was the difficulty in finding optimal values of two free parameters. The second method based on a median root prior has only one Bayesian parameter which was easy to set, but it should be taken into account that the image resolution while using that prior has to be chosen sufficiently high not to cause the complete removal of small spots. In conclusion, the Huber penalty function gives accurate and low noise images, but it may be difficult to determine the parameters. The median root prior method is not quite as accurate but may be used if image resolution is increased.